---
title: "Causal Forest"
author: "Filip Mellgren"
date: '2020-06-08'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Outline
In this project, I want to learn a bit about causal forests. The task is open ended and the  purpose is to learn while having fun. Consequently, I am not 100 percent sure where to take this project yet. Nontheless, here is a rough plan:

* Create a population as defined by some distribution.
* Introduce the notion of a treatment that we want to evaluate as scientists
    * This includes power calculation and selection of appropriately sized treatment group
    * Note the loss of power when looking for heterogenous treatment effects.
* Under the hood, define the treatment effect in such a way that individuals are affected differently.
* Carry out standard ATE calculation and evaluate results.
* Go a little bit deeper and see what can be done with a causal forest algorithm.

By doing this, I can hopefully obtain some knowledge on how to think about heterogenous treatment effects and good practice when designing experiments where we may care about how sub groups are affected differently. 

# Heterogenous treatment effects
Heterogenous treatment effects are typically studied using interaction terms that moderate a treatment variable. However, with many covariates, the number of possible combinations of interactrion effects makes the study loose statistical power, even before considering non-linear interaction effects.

```{r}
library(tidyverse); theme_set(theme_minimal())
library(MASS)
```

# Generate the population

God mode:

```{r population}
N <- 10^4
n_cols <- 10
covars <- sample(1:n_cols^2, n_cols^2)
Sigma <- matrix(covars,n_cols,n_cols) # covariance matrix. Diagonal indicates variances

# Ensure positive definiteness:
Sigma <-  t(Sigma) %*% Sigma

X <- mvrnorm(n = N, rep(0, n_cols), Sigma)

df <- X %>% as_tibble()
```

# Scientific preparations

```{r power_calc}
effect_size.min <- 0.1*mean(df$V1) # Lowest effect size we care about detecting.
sig.level <- 0.005 # Type I error porbability. 0.005 is best practice in behavioural economics
power <- 0.8 # 1 - Type II error probability. With 20% probability, we fail to reject false null, given the effect size above.
sd <- 0.01*sd(df$V1)

power_n <-  power.t.test(delta = effect_size.min, sd = sd, sig.level = sig.level, power = power, 
                               type = "two.sample", 
                               alternative = "two.sided")$n # number of observations required per group
power_n <- round(power_n)
```

```{r sample}
df.samp <- sample_n(df, 2*power_n)
```

Having drawn a sample from our population, we wish to first gain a bit of an understanding of the data available. For simplicity, we look at densities and bivariate linear relationships between our variables.

```{r EDA}
# Density of distributions
df.g <- df.samp %>% gather(key = "Variable", value = "Value")
df.g %>% ggplot(aes(x = Value, fill = Variable, alpha = 0.5)) + geom_density()
ggsave("images/densities.png")

# Bivariate relationships
cormat <- round(cor(df.samp),2)
melted_cormat <- reshape2::melt(cormat)
melted_cormat %>% ggplot(aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() +
  labs(title = "Correlation matrix", y = " ", x = " ")
```

```{r treatment}
# Randomly assign treatment within sample:
Treat1 <- rep(1, power_n)
Treat0 <- rep(0, power_n)
Treat <- sample_n(data.frame(c(Treat1, Treat0)), power_n*2)

df.samp <- as_tibble(cbind(df.samp, Treat$c.Treat1..Treat0.))

df.samp <- df.samp %>% rename(Treat = "Treat$c.Treat1..Treat0.")
```

At this point, the scientist injects a treatment into the treatment group, so let's play mother nature again and add an effect which heterogenously affects the population. That is, different people will react differently to the treatment.

```{r}
effect_size <- 1.2*effect_size.min # Slightly stronger than what we would minimally care about
df.samp$random_change <- rnorm(n = 2*power_n, sd = sd)

df.samp <-df.samp %>% mutate(V1_post = V1 + random_change +
                               Treat*effect_size*(1 + 0.01*V2/sd(V2) - 0.01*V3^2/sd(V3) + 0.01*V2*V3/(sd(V2)*sd(V3))))
```

Now that nature has run its course, let's see whether we first of all can detect the change using classical methods for obtaining the average treatment effect.

```{r}
df.samp %>% ggplot(aes(x = Treat, y = V1_post, color = as.factor(Treat))) + geom_boxplot()
df.samp %>% ggplot(aes(x = V1_post, color = as.factor(Treat))) + geom_density()

# Linear regression without covariates is ok because the expected conditional mean varies only with treatment status
linear_model <- lm(V1_post ~ V1 + Treat, data = df.samp)
summary(linear_model)

```
We find a statistically significant negative effect using the classic toolkit. Now let's turn to the causal forest and see whether we can learn about how it varies across different segments.

# Causal Forest

# Resources
Lechner on arxiv: https://arxiv.org/pdf/1812.09487.pdf

